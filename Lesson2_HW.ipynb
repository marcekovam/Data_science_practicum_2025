{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdUPdG_SKdaL"
   },
   "source": [
    "# HW02\n",
    "\n",
    "*Create your own image dataset and make it publicly available (2-5 categories, 100-300 images per category, cca 1000 images in total). Split it to train and test partitions (75% : 25%). See the required folder format below.*\n",
    "\n",
    "*Train a simple CNN on your dataset. It is ok if it is not optimal - we will improve it next week.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki8_obmfNaPB"
   },
   "source": [
    "## Create the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UsGFT13c7iI"
   },
   "source": [
    "### Search for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j7Z0NpfrKacU",
    "outputId": "7b924a07-4d70-4d1d-d864-2916f313b16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ddgs in /usr/local/lib/python3.12/dist-packages (9.6.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.2.1)\n",
      "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
      "Requirement already satisfied: lxml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
      "Requirement already satisfied: socksio==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "-yaRs7QeNfid"
   },
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "\n",
    "def search_images(keyword, max_results=10):\n",
    "  # Function to search images\n",
    "    with DDGS() as ddgs:\n",
    "        images = ddgs.images(\n",
    "            keyword,\n",
    "            max_results=max_results\n",
    "        )\n",
    "        return [img['image'] for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dZ54uuBWNuk3",
    "outputId": "6ef4fb7d-0e94-4473-f04a-c54af9f5f145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"pizza\"\n",
    "image_urls = search_images(keyword, 300)\n",
    "len(image_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-QFl2wLaSRR"
   },
   "source": [
    "The number of images does not match the number of requested images, because there are not so many available images or there is rate limiting by DuckDuckGo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1fueiIpcOrP_",
    "outputId": "d84fe3be-3dd9-4171-fe84-922156a2653e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://www.slicepizzeria.com/wp-content/uploads/2023/03/Pizza-Huts-HAND-TOSSED-Pizza-.jpg'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the URL of 51st image\n",
    "image_urls[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "EJVDzd58cpXB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Display the first 3 images\n",
    "for url in image_urls[:3]:\n",
    "    display(Image(url=url, width=150, height=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzAqco14dCwg"
   },
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "PjedUk81c0s-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "\n",
    "def download_image(url, folder, custom_name=None, verbose=True):\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Get the filename from the URL or use the custom name\n",
    "    if custom_name:\n",
    "        filename = custom_name\n",
    "    else:\n",
    "        filename = os.path.basename(urlparse(url).path)\n",
    "        if not filename:\n",
    "            filename = 'image.jpg'  # Default filename if none is found in the URL\n",
    "\n",
    "    # Ensure the filename has an extension\n",
    "    if not os.path.splitext(filename)[1]:\n",
    "        filename += '.jpg'\n",
    "\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    # If the file already exists, append a number to make it unique\n",
    "    base, extension = os.path.splitext(filepath)\n",
    "    counter = 1\n",
    "    while os.path.exists(filepath):\n",
    "        filepath = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "\n",
    "    try:\n",
    "        # Send a GET request to the URL with a timeout of 10 seconds\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "\n",
    "        # Check if the content type is an image\n",
    "        content_type = response.headers.get('content-type', '')\n",
    "        if not content_type.startswith('image'):\n",
    "            if verbose:\n",
    "                warnings.warn(f\"The URL does not point to an image. Content-Type: {content_type}\")\n",
    "            return False\n",
    "\n",
    "        # Write the image content to the file\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Image successfully downloaded: {filepath}\")\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        if verbose:\n",
    "            warnings.warn(f\"Download timed out for URL: {url}\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if verbose:\n",
    "            warnings.warn(f\"HTTP error occurred: {e}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if verbose:\n",
    "            warnings.warn(f\"An error occurred while downloading the image: {e}\")\n",
    "    except IOError as e:\n",
    "        if verbose:\n",
    "            warnings.warn(f\"An error occurred while writing the file: {e}\")\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tptcU9pXduyd"
   },
   "source": [
    "Let's download all the images we have found in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e726be4405f8403d989cade11fb30eae",
      "3a79e59df23d4628898127417f0c8ca4",
      "d03a3240a56c4ce9acd19fd3f8b779f5",
      "b453d47335df4fe3be01af8d7548b72b",
      "a457890fa16f4fda8b9328f6f81001f5",
      "86ec1cb934a1432e9495f1183420c2ff",
      "4e949ce0071e42ffad3f40a0e3acf080",
      "aae8d763a3d74acaaf5c23994103a9a7",
      "904633ec37b348c7a5d7f74e702ef65e",
      "7608d894a88245249ecdbd8879d173d0",
      "bbf99ad352d6481f910380bed9d6236d"
     ]
    },
    "id": "Dfe0zWIidmRM",
    "outputId": "488539b9-c6be-4c0c-cfc4-2681702a6f1f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e726be4405f8403d989cade11fb30eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i, url in enumerate(tqdm(image_urls)):\n",
    "    download_image(url, \"./dataset/pizza/\", f'image{i}.jpg', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBEeRtMofcuq"
   },
   "source": [
    "Now repeat the process for other categories of jummy food :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "840693bb605d4ad0abf5373571819ef8",
      "e18e43ed38d9416aa18a2d8caefa5617",
      "0f29e99181c8446381ee8b3f01da3c9e",
      "e70d7bd446344f009192e35de2395c46",
      "4b333680508944f88d2b40e05b529a98",
      "3d5912305a60416d9f2badb2f4db51a2",
      "b09f2283daf6466c8271babc75810ad2",
      "25607ace13cf437db72b08cdabe56e1a",
      "86977bf3f38f43ba9e41eb8bfca2db55",
      "4440f7ff423e42e4ba176c7bd96fdbad",
      "01c4e84097f24f529969b428d210bf48"
     ]
    },
    "id": "BqHHVB5rfZrr",
    "outputId": "7dc57aa0-2136-4013-b655-818f4b0ee64c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840693bb605d4ad0abf5373571819ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword = \"burger\"\n",
    "image_urls = search_images(keyword, 300)\n",
    "for i, url in enumerate(tqdm(image_urls)):\n",
    "    download_image(url, \"./dataset/burger/\", f'image{i}.jpg', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8858fa6786a94f8d846f3edcfd2ef7d0",
      "9f3321c3aa924efb9bedaa6a1666e726",
      "991213d9c98c45e6b4eba53d0b4f6710",
      "85e7cb49dae247abb99c66988d23e19f",
      "6cd728e4ed4b4cd98f88e4542e94ffba",
      "9021024bc489481f93f3eafa5892fe5e",
      "0ae39e5388a24dd18ea242e61bc514f0",
      "013d3a423eb64678b828b5b8513010f4",
      "c7c35a99911e44ed8dbb37d6f607aafd",
      "366903207a964cf98257853d351ba701",
      "0a64d3c0f77b407ca6afec957c6acbf0"
     ]
    },
    "id": "qA6m4KCfgT-O",
    "outputId": "da19fdb6-9a1b-44c6-9cb9-6e8aa8d6fb36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8858fa6786a94f8d846f3edcfd2ef7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword = \"pasta\"\n",
    "image_urls = search_images(keyword, 300)\n",
    "for i, url in enumerate(tqdm(image_urls)):\n",
    "    download_image(url, \"./dataset/pasta/\", f'image{i}.jpg', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a726ba8683e74b71abf49c1e421428a2",
      "fc6fd26bd0244115abf817a0f5975aeb",
      "bc5f2fbbb1604b2f9f945d713bb4f6ce",
      "3c6b54b4c14b4c318261178d8049824e",
      "90f4dcb894d14d079f889cd402621260",
      "0f0d356fb768429d82ad34bb939e1a52",
      "d884a86068c0446694eda9a3529690bf",
      "ca5039d9274f4b6380f578d548820b9b",
      "056abf8e09be464eae79d18b3a23ecc6",
      "542e36c2248044f393dd4c228a374242",
      "354e90f841b14e84903c44267fbe009c"
     ]
    },
    "id": "xftFQHsygne7",
    "outputId": "0b105654-e4b1-45b4-df2b-e495e5535a42"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a726ba8683e74b71abf49c1e421428a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword = \"sushi\"\n",
    "image_urls = search_images(keyword, 300)\n",
    "for i, url in enumerate(tqdm(image_urls)):\n",
    "    download_image(url, \"./dataset/sushi/\", f'image{i}.jpg', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhAdh7cSjDwv"
   },
   "source": [
    "Let's check the number of images in each category. There are only a few of them, even though we have requested more :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3IraxwViJIP",
    "outputId": "7da292c2-8946-452d-a475-0a2de2d3efb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza: 82\n",
      "Burger: 82\n",
      "Pasta: 67\n",
      "Sushi: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pizza: {len(os.listdir(\"./dataset/pizza/\"))}\")\n",
    "print(f\"Burger: {len(os.listdir(\"./dataset/burger/\"))}\")\n",
    "print(f\"Pasta: {len(os.listdir(\"./dataset/pasta/\"))}\")\n",
    "print(f\"Sushi: {len(os.listdir(\"./dataset/sushi/\"))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLK9vEcr7dWL"
   },
   "source": [
    "### Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "t5579H_p7oIK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "dataset_dir = \"/content/dataset\"  # original dataset folder\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# Create train/test folders if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# List categories\n",
    "categories = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "\n",
    "# Exclude train/test if they already exist\n",
    "categories = [c for c in categories if c not in [\"train\", \"test\"]]\n",
    "\n",
    "# Split ratio\n",
    "train_ratio = 0.75\n",
    "\n",
    "# Process each category\n",
    "for category in categories:\n",
    "    cat_path = os.path.join(dataset_dir, category)\n",
    "    images = [f for f in os.listdir(cat_path) if os.path.isfile(os.path.join(cat_path, f))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    split_idx = int(len(images) * train_ratio)\n",
    "    train_images = images[:split_idx]\n",
    "    test_images = images[split_idx:]\n",
    "\n",
    "    # Create category folders in train/test\n",
    "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "\n",
    "    # Move images\n",
    "    for img in train_images:\n",
    "        shutil.move(os.path.join(cat_path, img), os.path.join(train_dir, category, img))\n",
    "    for img in test_images:\n",
    "        shutil.move(os.path.join(cat_path, img), os.path.join(test_dir, category, img))\n",
    "\n",
    "    # Remove original empty category folder\n",
    "    os.rmdir(cat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Eigb9JlGL0w",
    "outputId": "2a3cfc6c-3fb7-4c63-d01f-4400d3a81e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "Pizza: 61\n",
      "Burger: 61\n",
      "Pasta: 50\n",
      "Sushi: 64\n",
      "\n",
      "TEST:\n",
      "Pizza: 21\n",
      "Burger: 21\n",
      "Pasta: 17\n",
      "Sushi: 22\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN:\")\n",
    "print(f\"Pizza: {len(os.listdir(\"./dataset/train/pizza/\"))}\")\n",
    "print(f\"Burger: {len(os.listdir(\"./dataset/train/burger/\"))}\")\n",
    "print(f\"Pasta: {len(os.listdir(\"./dataset/train/pasta/\"))}\")\n",
    "print(f\"Sushi: {len(os.listdir(\"./dataset/train/sushi/\"))}\")\n",
    "print(\"\\nTEST:\")\n",
    "print(f\"Pizza: {len(os.listdir(\"./dataset/test/pizza/\"))}\")\n",
    "print(f\"Burger: {len(os.listdir(\"./dataset/test/burger/\"))}\")\n",
    "print(f\"Pasta: {len(os.listdir(\"./dataset/test/pasta/\"))}\")\n",
    "print(f\"Sushi: {len(os.listdir(\"./dataset/test/sushi/\"))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmkfAsZjmsnH"
   },
   "source": [
    "### Make dataset publicly available\n",
    "\n",
    "Push dataset to GitHub repository to make it publicaly available. This option is only advisable if the dataset is not too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bdgs5p33iRVP",
    "outputId": "51c3041e-baef-4175-86d7-d204c1041c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331M\t./dataset\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the dataset\n",
    "!du -sh ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLMpKmJQzCme",
    "outputId": "7e4cf0ea-b280-47a0-80c1-7e1bea162a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install Git\n",
    "!apt-get install git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "u65RQyfmzN16"
   },
   "outputs": [],
   "source": [
    "# Configure Git\n",
    "!git config --global user.name \"marcekovam\"\n",
    "!git config --global user.email \"michaela.marcekova888@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsAoMTJdzkAe",
    "outputId": "85def20a-c92d-47e4-8e15-bf7bb3d49f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Data_science_practicum_2025'...\n",
      "remote: Enumerating objects: 426, done.\u001b[K\n",
      "remote: Total 426 (delta 0), reused 0 (delta 0), pack-reused 426 (from 1)\u001b[K\n",
      "Receiving objects: 100% (426/426), 192.79 MiB | 33.02 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n",
      "Updating files: 100% (322/322), done.\n",
      "/content/Data_science_practicum_2025/Data_science_practicum_2025/Data_science_practicum_2025\n"
     ]
    }
   ],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone https://github.com/marcekovam/Data_science_practicum_2025.git\n",
    "%cd Data_science_practicum_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "VYkymUvY0JSn"
   },
   "outputs": [],
   "source": [
    "# Copy dataset into the repo\n",
    "!cp -r /content/dataset ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JERWBZzB0VAy",
    "outputId": "2fcd99e1-1f2a-4671-ffbb-826025c5c949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 76c4ce2] Add dataset\n",
      " 317 files changed, 0 insertions(+), 0 deletions(-)\n",
      " create mode 100644 dataset/dataset/test/burger/image17.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image24.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image25.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image26.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image27.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image30.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image32.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image34.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image35.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image40.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image51.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image52.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image53.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image54.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image57.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image64.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image65.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image79.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image81.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image84.jpg\n",
      " create mode 100644 dataset/dataset/test/burger/image89.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image1.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image14.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image15.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image21.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image23.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image28.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image31.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image42.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image59.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image61.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image64.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image7.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image72.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image80.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image85.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image88.jpg\n",
      " create mode 100644 dataset/dataset/test/pasta/image97.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image0.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image10.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image21.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image22.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image23.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image42.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image45.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image49.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image52.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image54.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image56.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image63.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image76.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image79.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image8.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image82.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image83.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image87.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image88.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image9.jpg\n",
      " create mode 100644 dataset/dataset/test/pizza/image95.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image16.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image22.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image23.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image25.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image31.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image41.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image42.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image43.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image48.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image5.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image54.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image61.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image67.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image69.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image70.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image75.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image79.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image89.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image9.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image94.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image95.jpg\n",
      " create mode 100644 dataset/dataset/test/sushi/image96.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image1.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image10.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image11.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image12.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image16.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image18.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image19.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image20.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image21.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image22.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image23.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image28.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image29.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image3.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image31.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image33.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image36.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image37.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image39.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image4.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image41.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image42.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image43.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image44.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image47.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image48.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image49.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image5.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image50.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image55.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image56.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image58.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image59.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image60.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image62.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image63.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image67.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image68.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image69.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image7.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image70.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image71.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image73.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image74.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image75.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image76.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image77.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image78.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image8.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image82.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image83.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image87.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image88.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image9.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image90.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image92.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image94.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image95.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image97.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image98.jpg\n",
      " create mode 100644 dataset/dataset/train/burger/image99.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image11.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image13.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image17.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image18.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image24.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image25.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image26.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image27.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image29.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image3.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image33.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image34.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image37.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image38.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image39.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image4.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image41.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image44.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image45.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image47.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image48.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image51.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image53.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image55.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image56.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image57.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image58.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image6.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image60.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image62.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image63.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image65.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image70.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image71.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image73.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image74.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image75.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image76.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image77.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image8.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image82.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image84.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image86.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image89.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image9.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image90.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image92.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image95.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image96.jpg\n",
      " create mode 100644 dataset/dataset/train/pasta/image98.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image1.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image12.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image14.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image15.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image16.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image19.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image2.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image20.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image24.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image25.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image26.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image27.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image3.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image31.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image32.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image33.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image34.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image35.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image36.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image37.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image38.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image39.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image4.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image40.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image41.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image43.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image44.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image47.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image5.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image50.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image51.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image57.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image58.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image6.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image60.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image61.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image62.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image64.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image65.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image67.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image68.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image70.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image71.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image72.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image73.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image74.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image75.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image77.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image78.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image80.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image81.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image84.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image85.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image86.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image90.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image91.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image92.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image93.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image96.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image98.jpg\n",
      " create mode 100644 dataset/dataset/train/pizza/image99.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image10.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image11.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image12.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image15.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image17.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image18.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image19.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image2.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image20.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image21.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image24.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image26.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image27.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image28.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image29.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image30.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image32.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image33.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image34.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image35.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image36.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image37.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image38.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image4.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image44.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image45.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image46.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image47.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image49.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image50.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image51.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image52.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image53.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image55.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image56.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image57.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image58.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image59.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image6.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image60.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image62.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image63.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image65.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image66.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image7.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image71.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image72.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image73.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image74.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image76.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image77.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image80.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image81.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image82.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image84.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image86.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image87.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image88.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image90.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image91.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image92.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image93.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image97.jpg\n",
      " create mode 100644 dataset/dataset/train/sushi/image98.jpg\n"
     ]
    }
   ],
   "source": [
    "# Stage and commit the files\n",
    "!git add dataset  # or the folder\n",
    "!git commit -m \"Add dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpH_RuEj17m5",
    "outputId": "896da910-2001-42b5-b6be-0bfd266c163b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 5, done.\n",
      "Counting objects:  20% (1/5)\r",
      "Counting objects:  40% (2/5)\r",
      "Counting objects:  60% (3/5)\r",
      "Counting objects:  80% (4/5)\r",
      "Counting objects: 100% (5/5)\r",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects:  33% (1/3)\r",
      "Compressing objects:  66% (2/3)\r",
      "Compressing objects: 100% (3/3)\r",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects:  33% (1/3)\r",
      "Writing objects:  66% (2/3)\r",
      "Writing objects: 100% (3/3)\r",
      "Writing objects: 100% (3/3), 348 bytes | 348.00 KiB/s, done.\n",
      "Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas:   0% (0/1)\u001b[K\r",
      "remote: Resolving deltas: 100% (1/1)\u001b[K\r",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/marcekovam/Data_science_practicum_2025.git\n",
      "   2c70811..76c4ce2  main -> main\n"
     ]
    }
   ],
   "source": [
    "# Push to GitHub\n",
    "# Includes PAT (personal access token) generated in GitHub Developer settings\n",
    "!git push https://marcekovam:MY_PAT@github.com/marcekovam/Data_science_practicum_2025.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "btAgWg_52UCf"
   },
   "outputs": [],
   "source": [
    "# Now anyone can clone my repo to access the dataset\n",
    "# git clone https://github.com/marcekovam/Data_science_practicum_2025.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVr27UbX6Jwj"
   },
   "source": [
    "## Neural network (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2chbXlmLCxF"
   },
   "source": [
    "*Train a simple CNN on your dataset. It is ok if it is not optimal - we will improve it next week.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_xVFli0X7Pz"
   },
   "source": [
    "### Data preparation for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTVDHo9_MdkU"
   },
   "source": [
    "The images have different sizes. First, we have to down size them to 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdTq8mf2NmRS",
    "outputId": "31bfeaa9-c9d7-4a62-ec75-b979552a0ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "# Change directory from repo to content\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jh86iOxCM8Ok",
    "outputId": "12e3e454-6c1c-4428-f853-4bb1fd7fa35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classes: ['burger', 'pasta', 'pizza', 'sushi']\n",
      "Number of training samples: 236\n",
      "Number of testing samples: 81\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data transformation:\n",
    "## Down size images\n",
    "## Convert images to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the training data\n",
    "train_set = datasets.ImageFolder(root='./dataset/train', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "\n",
    "# Load the testing data\n",
    "test_set = datasets.ImageFolder(root='./dataset/test', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Training classes:\", train_set.classes)\n",
    "print(\"Number of training samples:\", len(train_set))\n",
    "print(\"Number of testing samples:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onAAGGnlXNr3"
   },
   "source": [
    "Let's look at the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "IDobTsfwVjU1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Path to pizza images in train folder\n",
    "pizza_dir = \"/content/dataset/train/pizza\"\n",
    "images = os.listdir(pizza_dir)\n",
    "\n",
    "# Sort files to get a consistent first image\n",
    "images.sort()\n",
    "first_image_path = os.path.join(pizza_dir, images[0])\n",
    "\n",
    "# Read and display the image\n",
    "img = mpimg.imread(first_image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O2qSGt3XSuT"
   },
   "source": [
    "Let's see its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29huGWA0WLJ5",
    "outputId": "67f2f230-3c85-47c0-9db4-5a0bb5ebd9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 3888, Height: 2592\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the first image\n",
    "img = Image.open(first_image_path)\n",
    "\n",
    "# Get size\n",
    "width, height = img.size\n",
    "print(f\"Width: {width}, Height: {height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfmbTfNWXWiG"
   },
   "source": [
    "The images seem unchanged. That's because it applies the transform only when loading images during training - it does not physically resize the images.\n",
    "\n",
    "So the code is fine, but the images remain the original size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA97xEc1YCZj"
   },
   "source": [
    "### Libraries and GPU setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRxOQyolLQ2U"
   },
   "source": [
    "Import libraries for convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "HzxXXPS3LjLs"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msZE0r_zZEJO"
   },
   "source": [
    "This code checks if a CUDA-enabled GPU is available and sets the device accordingly. If no GPU is available, it defaults to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh-me29OYsJs",
    "outputId": "a5d9c262-901e-4c5b-9989-b9b64316779d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCZVIPSgZzOa"
   },
   "source": [
    "### Convolutional neural network (CNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZzjAEV5Z6vP"
   },
   "source": [
    "*Do not forget the images are RGB, not greyscale as FashionMNIST. Therefore, they will have three channels on input, not one.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5smmzgpspPI1"
   },
   "source": [
    "In PyTorch, images are represented as 4D tensors with the shape:\n",
    "\n",
    "$$\n",
    "\\text{(batch_size, channels, height, width)}\n",
    "$$\n",
    "\n",
    "* batch\\_size - number of images in one batch,\n",
    "* channels - number of color channels:\n",
    "\n",
    "  * 1 ... black & white,\n",
    "  * 3 ... RGB images,\n",
    "* height and width - dimensions of the image.\n",
    "\n",
    "For example, 256 RGB images, each 2828 pixels, the shape is:\n",
    "\n",
    "$$\n",
    "(256, 3, 28, 28)\n",
    "$$\n",
    "\n",
    "The formula for output height/width is\n",
    "$$\\text{Output size} = \\frac{W - K + 2P}{S} + 1$$\n",
    "Where:\n",
    "  * $W$ ... input width/height,\n",
    "  * $K$ ... kernel size,\n",
    "  * $P$ ... padding (default = 0),\n",
    "  * $S$ ... stride (default = 1).\n",
    "\n",
    "Flatten takes the last three dimensions and turns them into one long vector (multiplication).\n",
    "\n",
    "This CNN transforms the shape like this:\n",
    "```\n",
    "Input Image: (batch_size, 3, 28, 28)\n",
    "After Conv1: (batch_size, 16, 28, 28)\n",
    "After Conv2: (batch_size, 32, 26, 26)\n",
    "Flatten Layer: (batch_size, 32 * 26 * 26 = 21,632)\n",
    "Fully Connected Layer: (batch_size, 64)\n",
    "Dropout: (batch_size, 64)\n",
    "Final Fully Connected Layer: (batch_size, 4)\n",
    "```\n",
    "\n",
    "`out_features=4` because there are 4 categories:\n",
    "  * pizza,\n",
    "  * burger,\n",
    "  * pasta,\n",
    "  * sushi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZR-T2TkncM0B",
    "outputId": "d0a00ed4-b7d9-49a8-ec9a-432228adf269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=21632, out_features=64, bias=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the simple CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input channels = 3 (RGB), output channels = 16\n",
    "        # in_channel = 1 ... for black-white image\n",
    "        # in_channel = 3 ... for RGB\n",
    "        # kernel_size = 3 ... matrix of convolution 3x3 to connect adjuscent pixels into one point\n",
    "        # padding = 1 ... adds 1-pixel padding around the input so the output size stays the same\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.flat = nn.Flatten()\n",
    "        # Converts the 2D feature maps into a 1D vector, so it proceed to fully connected layer\n",
    "        # Shape before flatten: (batch_size, 32, 26, 26)\n",
    "        # Shape after flatten:  (batch_size, 32*26*26)\n",
    "        # 28*28 was the image size, but in last layer it changed to 26*26\n",
    "        self.fc1 = nn.Linear(in_features=26*26*32, out_features=64)\n",
    "        self.drop = nn.Dropout(0.10)\n",
    "        # Randomly turns off 10% of neurons during training to prevent overfitting\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=4)\n",
    "        # out_features=4 ... number of categories (pizza, burger, pasta, sushi)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # ReLu after 1st convolution\n",
    "        x = F.relu(self.conv2(x))   # ReLu after 2nd convolution\n",
    "        x = self.flat(x)            # Flatten to get vector\n",
    "        x = F.relu(self.fc1(x))     # ReLu after Fully connected hidden layer\n",
    "        x = self.drop(x)            # Dropout to prevent overfitting\n",
    "        x = self.fc2(x)             # Final output layer\n",
    "        return x\n",
    "        # F.relu() ... Rectified Linear Unit activation:\n",
    "        # ReLU(x)=max(0,x)\n",
    "        # Adds non-linearity to the network\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUybGI6-tokj"
   },
   "source": [
    "### Loss & Optimizer\n",
    "\n",
    "`criterion`:\n",
    "CNN outputs raw scores (logits), not probabilities. The loss function `nn.CrossEntropyLoss` transforms them into probabilities through softmax function (exp devided by sum of exp) and computes negative log likelihood (we want to minimize this).\n",
    "\n",
    "`optimizer`:\n",
    "The optimizer updates the model weights to reduce the loss. The learning rate controls how big each update step is. Typical values: 0.1 for simple models, 0.01 and less for complex models (says chatGPT, Idk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "u70JbsKjYRhN"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFKi9zz9vdsq"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNtUDZW5vZlS",
    "outputId": "57015c26-f2f5-4bad-ee9b-bfa56a7eb135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.3864\n",
      "Epoch [2/5], Loss: 1.3836\n",
      "Epoch [3/5], Loss: 1.3813\n",
      "Epoch [4/5], Loss: 1.3790\n",
      "Epoch [5/5], Loss: 1.3755\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # Train for 5 epochs\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)  # pass images to model\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()  # compute the gradient\n",
    "        optimizer.step()  # change the parameters to \"better\" values\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjUVkmqKwHaX"
   },
   "source": [
    "The loss should be decreasing, if there are no underlying problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOGbFoV7ygAs"
   },
   "source": [
    "### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KqsW98gwOKu",
    "outputId": "d7eabc89-6e34-45e8-d68f-4c47e332fc79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n",
      "36 correctly classified images out of  total 81 test images\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        # Move images and labels to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "print(f'{correct} correctly classified images out of  total {total} test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkqZntcm1w-R"
   },
   "source": [
    "This accuracy doesn't seem that great, but it is much better then the previous results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrOpv23M2EOE"
   },
   "source": [
    "Fancy chatGPT code follows: let us see the correctly and incorrectly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-VnF7413YRF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one batch from the test loader\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Get predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Move to CPU for plotting\n",
    "images = images.cpu()\n",
    "labels = labels.cpu()\n",
    "predicted = predicted.cpu()\n",
    "\n",
    "# Show first 3 correct images\n",
    "plt.figure(figsize=(8, 3))\n",
    "count = 0\n",
    "for i in range(len(images)):\n",
    "    if predicted[i] == labels[i]:\n",
    "        plt.subplot(1, 5, count+1)\n",
    "        img = images[i].permute(1, 2, 0)  # CHW  HWC\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {train_set.classes[labels[i]]}\\nPred: {train_set.classes[predicted[i]]}\")\n",
    "        plt.axis('off')\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            break\n",
    "plt.suptitle(\"Correctly Classified Images\")\n",
    "plt.show()\n",
    "\n",
    "# Show first 3 incorrect images\n",
    "plt.figure(figsize=(8, 3))\n",
    "count = 0\n",
    "for i in range(len(images)):\n",
    "    if predicted[i] != labels[i]:\n",
    "        plt.subplot(1, 5, count+1)\n",
    "        img = images[i].permute(1, 2, 0)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {train_set.classes[labels[i]]}\\nPred: {train_set.classes[predicted[i]]}\")\n",
    "        plt.axis('off')\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            break\n",
    "plt.suptitle(\"Incorrectly Classified Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
